{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras \n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, LSTM, Activation\n",
    "from keras import backend as K\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.regularizers import l1_l2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.409480</td>\n",
       "      <td>0.330053</td>\n",
       "      <td>0.588166</td>\n",
       "      <td>-0.058139</td>\n",
       "      <td>-0.359565</td>\n",
       "      <td>0.061654</td>\n",
       "      <td>0.783157</td>\n",
       "      <td>0.434004</td>\n",
       "      <td>0.049200</td>\n",
       "      <td>0.890888</td>\n",
       "      <td>...</td>\n",
       "      <td>0.892950</td>\n",
       "      <td>-0.767745</td>\n",
       "      <td>0.439113</td>\n",
       "      <td>0.365136</td>\n",
       "      <td>0.573477</td>\n",
       "      <td>0.695570</td>\n",
       "      <td>-0.724616</td>\n",
       "      <td>0.458630</td>\n",
       "      <td>0.611607</td>\n",
       "      <td>0.826896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.533911</td>\n",
       "      <td>0.643805</td>\n",
       "      <td>0.901475</td>\n",
       "      <td>0.143997</td>\n",
       "      <td>0.013035</td>\n",
       "      <td>-0.379633</td>\n",
       "      <td>0.730578</td>\n",
       "      <td>0.515096</td>\n",
       "      <td>0.347368</td>\n",
       "      <td>0.935897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.787014</td>\n",
       "      <td>-0.724356</td>\n",
       "      <td>0.284720</td>\n",
       "      <td>0.818754</td>\n",
       "      <td>0.730015</td>\n",
       "      <td>0.524863</td>\n",
       "      <td>-0.262078</td>\n",
       "      <td>0.392839</td>\n",
       "      <td>0.289762</td>\n",
       "      <td>0.825478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.509951</td>\n",
       "      <td>0.666751</td>\n",
       "      <td>0.907186</td>\n",
       "      <td>0.363035</td>\n",
       "      <td>0.070572</td>\n",
       "      <td>-0.687706</td>\n",
       "      <td>0.727476</td>\n",
       "      <td>0.427720</td>\n",
       "      <td>0.543863</td>\n",
       "      <td>0.912617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.538350</td>\n",
       "      <td>0.519184</td>\n",
       "      <td>0.546229</td>\n",
       "      <td>0.941528</td>\n",
       "      <td>0.787032</td>\n",
       "      <td>-0.364118</td>\n",
       "      <td>0.216141</td>\n",
       "      <td>0.176713</td>\n",
       "      <td>0.060211</td>\n",
       "      <td>0.789942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.240762</td>\n",
       "      <td>0.831359</td>\n",
       "      <td>0.661822</td>\n",
       "      <td>0.248816</td>\n",
       "      <td>0.096252</td>\n",
       "      <td>-0.365287</td>\n",
       "      <td>0.473186</td>\n",
       "      <td>0.073838</td>\n",
       "      <td>0.828981</td>\n",
       "      <td>0.782181</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.526119</td>\n",
       "      <td>0.647022</td>\n",
       "      <td>0.264069</td>\n",
       "      <td>0.884479</td>\n",
       "      <td>0.790552</td>\n",
       "      <td>-0.740754</td>\n",
       "      <td>0.134361</td>\n",
       "      <td>0.530370</td>\n",
       "      <td>0.342484</td>\n",
       "      <td>0.852868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.187797</td>\n",
       "      <td>0.760324</td>\n",
       "      <td>0.483309</td>\n",
       "      <td>0.194137</td>\n",
       "      <td>0.020227</td>\n",
       "      <td>0.496607</td>\n",
       "      <td>0.460802</td>\n",
       "      <td>0.076955</td>\n",
       "      <td>0.879658</td>\n",
       "      <td>0.543056</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.733004</td>\n",
       "      <td>0.453606</td>\n",
       "      <td>0.239479</td>\n",
       "      <td>0.868984</td>\n",
       "      <td>0.641466</td>\n",
       "      <td>-0.804020</td>\n",
       "      <td>0.340424</td>\n",
       "      <td>0.616168</td>\n",
       "      <td>0.640221</td>\n",
       "      <td>0.776289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55870</td>\n",
       "      <td>0.252430</td>\n",
       "      <td>-0.371339</td>\n",
       "      <td>0.337835</td>\n",
       "      <td>-0.069046</td>\n",
       "      <td>-0.220030</td>\n",
       "      <td>0.174933</td>\n",
       "      <td>0.475429</td>\n",
       "      <td>0.192603</td>\n",
       "      <td>0.816235</td>\n",
       "      <td>-0.536560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.649733</td>\n",
       "      <td>0.813218</td>\n",
       "      <td>-0.451405</td>\n",
       "      <td>0.396054</td>\n",
       "      <td>0.541864</td>\n",
       "      <td>0.693254</td>\n",
       "      <td>-0.839364</td>\n",
       "      <td>0.218996</td>\n",
       "      <td>-0.412561</td>\n",
       "      <td>0.511329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55871</td>\n",
       "      <td>0.651506</td>\n",
       "      <td>-0.681530</td>\n",
       "      <td>0.853833</td>\n",
       "      <td>0.002269</td>\n",
       "      <td>-0.028894</td>\n",
       "      <td>0.440940</td>\n",
       "      <td>0.597065</td>\n",
       "      <td>-0.161940</td>\n",
       "      <td>0.099349</td>\n",
       "      <td>0.674637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248615</td>\n",
       "      <td>0.859941</td>\n",
       "      <td>-0.517496</td>\n",
       "      <td>0.586106</td>\n",
       "      <td>-0.085536</td>\n",
       "      <td>0.527270</td>\n",
       "      <td>-0.477805</td>\n",
       "      <td>0.318596</td>\n",
       "      <td>0.290935</td>\n",
       "      <td>0.737237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55872</td>\n",
       "      <td>0.357015</td>\n",
       "      <td>-0.478252</td>\n",
       "      <td>0.884538</td>\n",
       "      <td>0.095827</td>\n",
       "      <td>-0.070810</td>\n",
       "      <td>0.753470</td>\n",
       "      <td>0.732722</td>\n",
       "      <td>0.139935</td>\n",
       "      <td>-0.613398</td>\n",
       "      <td>0.642679</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005278</td>\n",
       "      <td>-0.265326</td>\n",
       "      <td>0.337169</td>\n",
       "      <td>-0.170902</td>\n",
       "      <td>-0.483197</td>\n",
       "      <td>-0.478460</td>\n",
       "      <td>0.013249</td>\n",
       "      <td>-0.413465</td>\n",
       "      <td>0.340715</td>\n",
       "      <td>0.650361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55873</td>\n",
       "      <td>0.323493</td>\n",
       "      <td>-0.257720</td>\n",
       "      <td>0.808529</td>\n",
       "      <td>-0.053447</td>\n",
       "      <td>0.058645</td>\n",
       "      <td>0.378627</td>\n",
       "      <td>0.448387</td>\n",
       "      <td>0.528075</td>\n",
       "      <td>-0.796151</td>\n",
       "      <td>0.662209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.290560</td>\n",
       "      <td>-0.432021</td>\n",
       "      <td>0.435367</td>\n",
       "      <td>0.365950</td>\n",
       "      <td>0.096495</td>\n",
       "      <td>-0.820756</td>\n",
       "      <td>0.009772</td>\n",
       "      <td>-0.566893</td>\n",
       "      <td>0.428987</td>\n",
       "      <td>0.718649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55874</td>\n",
       "      <td>-0.038965</td>\n",
       "      <td>0.177840</td>\n",
       "      <td>0.653042</td>\n",
       "      <td>-0.052196</td>\n",
       "      <td>0.351198</td>\n",
       "      <td>0.281742</td>\n",
       "      <td>0.024279</td>\n",
       "      <td>0.557168</td>\n",
       "      <td>-0.755097</td>\n",
       "      <td>0.724485</td>\n",
       "      <td>...</td>\n",
       "      <td>0.713169</td>\n",
       "      <td>-0.340811</td>\n",
       "      <td>0.278550</td>\n",
       "      <td>0.542900</td>\n",
       "      <td>0.503629</td>\n",
       "      <td>-0.854279</td>\n",
       "      <td>0.092350</td>\n",
       "      <td>-0.619892</td>\n",
       "      <td>0.493122</td>\n",
       "      <td>0.793269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55875 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              1         2         3         4         5         6         7  \\\n",
       "0      0.409480  0.330053  0.588166 -0.058139 -0.359565  0.061654  0.783157   \n",
       "1      0.533911  0.643805  0.901475  0.143997  0.013035 -0.379633  0.730578   \n",
       "2      0.509951  0.666751  0.907186  0.363035  0.070572 -0.687706  0.727476   \n",
       "3      0.240762  0.831359  0.661822  0.248816  0.096252 -0.365287  0.473186   \n",
       "4      0.187797  0.760324  0.483309  0.194137  0.020227  0.496607  0.460802   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "55870  0.252430 -0.371339  0.337835 -0.069046 -0.220030  0.174933  0.475429   \n",
       "55871  0.651506 -0.681530  0.853833  0.002269 -0.028894  0.440940  0.597065   \n",
       "55872  0.357015 -0.478252  0.884538  0.095827 -0.070810  0.753470  0.732722   \n",
       "55873  0.323493 -0.257720  0.808529 -0.053447  0.058645  0.378627  0.448387   \n",
       "55874 -0.038965  0.177840  0.653042 -0.052196  0.351198  0.281742  0.024279   \n",
       "\n",
       "              8         9        10  ...        12        13        14  \\\n",
       "0      0.434004  0.049200  0.890888  ...  0.892950 -0.767745  0.439113   \n",
       "1      0.515096  0.347368  0.935897  ...  0.787014 -0.724356  0.284720   \n",
       "2      0.427720  0.543863  0.912617  ...  0.538350  0.519184  0.546229   \n",
       "3      0.073838  0.828981  0.782181  ... -0.526119  0.647022  0.264069   \n",
       "4      0.076955  0.879658  0.543056  ... -0.733004  0.453606  0.239479   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "55870  0.192603  0.816235 -0.536560  ...  0.649733  0.813218 -0.451405   \n",
       "55871 -0.161940  0.099349  0.674637  ...  0.248615  0.859941 -0.517496   \n",
       "55872  0.139935 -0.613398  0.642679  ... -0.005278 -0.265326  0.337169   \n",
       "55873  0.528075 -0.796151  0.662209  ...  0.290560 -0.432021  0.435367   \n",
       "55874  0.557168 -0.755097  0.724485  ...  0.713169 -0.340811  0.278550   \n",
       "\n",
       "             15        16        17        18        19        20        21  \n",
       "0      0.365136  0.573477  0.695570 -0.724616  0.458630  0.611607  0.826896  \n",
       "1      0.818754  0.730015  0.524863 -0.262078  0.392839  0.289762  0.825478  \n",
       "2      0.941528  0.787032 -0.364118  0.216141  0.176713  0.060211  0.789942  \n",
       "3      0.884479  0.790552 -0.740754  0.134361  0.530370  0.342484  0.852868  \n",
       "4      0.868984  0.641466 -0.804020  0.340424  0.616168  0.640221  0.776289  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "55870  0.396054  0.541864  0.693254 -0.839364  0.218996 -0.412561  0.511329  \n",
       "55871  0.586106 -0.085536  0.527270 -0.477805  0.318596  0.290935  0.737237  \n",
       "55872 -0.170902 -0.483197 -0.478460  0.013249 -0.413465  0.340715  0.650361  \n",
       "55873  0.365950  0.096495 -0.820756  0.009772 -0.566893  0.428987  0.718649  \n",
       "55874  0.542900  0.503629 -0.854279  0.092350 -0.619892  0.493122  0.793269  \n",
       "\n",
       "[55875 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev = pd.read_csv(\"D:/Course content/Minor Project/TDT_Data/Validation.csv\")\n",
    "dev.rename( columns={'Unnamed: 0':'0'}, inplace=True )\n",
    "dev.drop('0', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "dev_X = dev.drop(['0','21'], axis = 1)\n",
    "dev_y = dev['21'].copy()\n",
    "dev_X.to_csv('D:/Course content/Minor Project/TDT_Data/X_Y_Split/Validation_X.csv')\n",
    "dev_y.to_csv('D:/Course content/Minor Project/TDT_Data/X_Y_Split/Validation_y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"D:/Course content/Minor Project/TDT_Data/Train.csv\")\n",
    "train.rename( columns={'Unnamed: 0':'d'}, inplace=True )\n",
    "train_X = train.drop(['d','20'], axis = 1)\n",
    "train_X.to_csv('D:/Course content/Minor Project/TDT_Data/X_Y_Split/Train_X.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train_y = train['20'].copy()\n",
    "train_y.to_csv('D:/Course content/Minor Project/TDT_Data/X_Y_Split/Train_Y.csv')\n",
    "pd.DataFrame(train_y).to_csv('D:/Course content/Minor Project/TDT_Data/X_Y_Split/Train_Y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_X = dev_X.loc[:, ~dev_X.columns.str.contains('^Unnamed')]\n",
    "train_X = train_X.loc[:, ~dev_X.columns.str.contains('^Unnamed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP = 20\n",
    "_dev_X = np.asarray(dev_X).reshape((int(1117500/STEP), 20 , 1))\n",
    "_dev_Y = np.asarray(dev_y).reshape(int(1117500/STEP), 1)\n",
    "_train_X = np.asarray(train_X).reshape((int(1117500/STEP), 20, 1))\n",
    "_train_Y = np.asarray(train_y).reshape(int(1117500/STEP), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"D:/Course content/Minor Project/TDT_Data/Test1.csv\")\n",
    "test.rename( columns={'Unnamed: 0':'d'}, inplace=True )\n",
    "test_X = test.drop(['d','22'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "test_y = test['22'].copy()\n",
    "test_X.to_csv('D:/Course content/Minor Project/TDT_Data/X_Y_Split/Test_X.csv')\n",
    "test_y.to_csv('D:/Course content/Minor Project/TDT_Data/X_Y_Split/Test_Y.csv')\n",
    "_test_X = np.asarray(test_X).reshape((int(1117500/STEP), 20, 1))\n",
    "_test_Y = np.asarray(test_y).reshape(int(1117500/STEP), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "112/112 [==============================] - 311s 3s/step - loss: 0.3364 - mse: 0.3364 - mae: 0.4571\n",
      "history : {'loss': [0.3364291489124298], 'mse': [0.3364291489124298], 'mae': [0.45714402198791504]}\n",
      "1747/1747 [==============================] - 150s 86ms/step - loss: 0.2217 - mse: 0.2217 - mae: 0.4019\n",
      "1747/1747 [==============================] - 168s 96ms/step - loss: 0.2529 - mse: 0.2529 - mae: 0.43861s - loss: 0.2530 - mse: 0.2530 - \n",
      "1747/1747 [==============================] - 133s 76ms/step - loss: 0.2565 - mse: 0.2565 - mae: 0.4462\n",
      "train set score : mse - 0.22165408730506897 / mae - 0.40185749530792236\n",
      "dev set score : mse - 0.2528919279575348 / mae - 0.43856319785118103\n",
      "test set score : mse - 0.25647401809692383 / mae - 0.44623422622680664\n",
      "112/112 [==============================] - 230s 2s/step - loss: 0.2215 - mse: 0.2215 - mae: 0.4006\n",
      "history : {'loss': [0.22149614989757538], 'mse': [0.22149614989757538], 'mae': [0.40055176615715027]}\n",
      "1747/1747 [==============================] - 130s 74ms/step - loss: 0.2211 - mse: 0.2211 - mae: 0.4012\n",
      "1747/1747 [==============================] - 141s 81ms/step - loss: 0.2539 - mse: 0.2539 - mae: 0.4397\n",
      "1747/1747 [==============================] - 139s 80ms/step - loss: 0.2564 - mse: 0.2564 - mae: 0.4469\n",
      "train set score : mse - 0.22105346620082855 / mae - 0.4012467563152313\n",
      "dev set score : mse - 0.25393417477607727 / mae - 0.43966421484947205\n",
      "test set score : mse - 0.25644344091415405 / mae - 0.4468655586242676\n",
      "112/112 [==============================] - 248s 2s/step - loss: 0.2211 - mse: 0.2211 - mae: 0.4004\n",
      "history : {'loss': [0.22113379836082458], 'mse': [0.22113379836082458], 'mae': [0.40037408471107483]}\n",
      "1747/1747 [==============================] - 131s 75ms/step - loss: 0.2240 - mse: 0.2240 - mae: 0.39958s - loss: 0.22 - ETA: 6s -  - ETA: 3s - loss: 0 - ETA: 0s - loss: 0.2243 - mse: 0.2243 - \n",
      "1747/1747 [==============================] - 136s 78ms/step - loss: 0.2436 - mse: 0.2436 - mae: 0.4250\n",
      "1747/1747 [==============================] - 135s 77ms/step - loss: 0.2232 - mse: 0.2232 - mae: 0.4134\n",
      "train set score : mse - 0.22404445707798004 / mae - 0.39946234226226807\n",
      "dev set score : mse - 0.24355532228946686 / mae - 0.4250091016292572\n",
      "test set score : mse - 0.22322838008403778 / mae - 0.41343048214912415\n",
      "112/112 [==============================] - 236s 2s/step - loss: 0.2219 - mse: 0.2219 - mae: 0.4010\n",
      "history : {'loss': [0.22192242741584778], 'mse': [0.22192242741584778], 'mae': [0.4010118544101715]}\n",
      "1747/1747 [==============================] - 132s 76ms/step - loss: 0.2223 - mse: 0.2223 - mae: 0.3992\n",
      "1747/1747 [==============================] - 132s 76ms/step - loss: 0.2435 - mse: 0.2435 - mae: 0.4267\n",
      "1747/1747 [==============================] - 136s 78ms/step - loss: 0.2251 - mse: 0.2251 - mae: 0.4159\n",
      "train set score : mse - 0.22232790291309357 / mae - 0.399168998003006\n",
      "dev set score : mse - 0.24350129067897797 / mae - 0.42669928073883057\n",
      "test set score : mse - 0.22506535053253174 / mae - 0.4158702790737152\n",
      "112/112 [==============================] - 212s 2s/step - loss: 0.2214 - mse: 0.2214 - mae: 0.4004\n",
      "history : {'loss': [0.22140049934387207], 'mse': [0.22140049934387207], 'mae': [0.400441437959671]}\n",
      "1747/1747 [==============================] - 121s 69ms/step - loss: 0.2244 - mse: 0.2244 - mae: 0.4048\n",
      "1747/1747 [==============================] - 119s 68ms/step - loss: 0.2609 - mse: 0.2609 - mae: 0.4465\n",
      "1747/1747 [==============================] - 122s 70ms/step - loss: 0.2738 - mse: 0.2738 - mae: 0.4616\n",
      "train set score : mse - 0.22437416017055511 / mae - 0.4048357903957367\n",
      "dev set score : mse - 0.26085153222084045 / mae - 0.44652852416038513\n",
      "test set score : mse - 0.27377206087112427 / mae - 0.46159371733665466\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Flatten\n",
    "#define custom activation\n",
    "class Double_Tanh(Activation):\n",
    "    def __init__(self, activation, **kwargs):\n",
    "        super(Double_Tanh, self).__init__(activation, **kwargs)\n",
    "        self.__name__ = 'double_tanh'\n",
    "\n",
    "def double_tanh(x):\n",
    "    return (K.tanh(x))\n",
    "\n",
    "get_custom_objects().update({'double_tanh':Double_Tanh(double_tanh)})\n",
    "\n",
    "# Model Generation\n",
    "model = Sequential()\n",
    "model.add(Dense(55875, input_shape=(20, 1), activation='double_tanh'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1))\n",
    "# model.add(Activation(double_tanh))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse', 'mae'])\n",
    "\n",
    "print(model.metrics_names)\n",
    "# Fitting the Model\n",
    "model_scores = {}\n",
    "score_list =[]\n",
    "Reg = False\n",
    "d = 'MLP'\n",
    "\n",
    "if Reg :\n",
    "    d += '_with_reg'\n",
    "\n",
    "epoch_num=1\n",
    "for _ in range(5):\n",
    "\n",
    "    # train the model\n",
    "    m = model.fit(_train_X, _train_Y, epochs=1, batch_size=500, shuffle=True)\n",
    "    print('history :', m.history)\n",
    "    score_list.append(m.history)\n",
    "\n",
    "    # test the model\n",
    "    score_train = model.evaluate(_train_X, _train_Y)\n",
    "    score_dev = model.evaluate(_dev_X, _dev_Y)\n",
    "    score_test1 = model.evaluate(_test_X, _test_Y)\n",
    "\n",
    "    print('train set score : mse - ' + str(score_train[1]) +' / mae - ' + str(score_train[2]))\n",
    "    print('dev set score : mse - ' + str(score_dev[1]) +' / mae - ' + str(score_dev[2]))\n",
    "    print('test set score : mse - ' + str(score_test1[1]) +' / mae - ' + str(score_test1[2]))\n",
    "    df = pd.read_csv(\"D:/Course content/Minor Project/models/\"+d+\".csv\")\n",
    "    train_mse = list(df['TRAIN_MSE'])\n",
    "    dev_mse = list(df['DEV_MSE'])\n",
    "    test1_mse = list(df['TEST1_MSE'])\n",
    "\n",
    "\n",
    "    train_mae = list(df['TRAIN_MAE'])\n",
    "    dev_mae = list(df['DEV_MAE'])\n",
    "    test1_mae = list(df['TEST1_MAE'])\n",
    "\n",
    "    # append new data\n",
    "    train_mse.append(score_train[1])\n",
    "    dev_mse.append(score_dev[1])\n",
    "    test1_mse.append(score_test1[1])\n",
    "\n",
    "    train_mae.append(score_train[2])\n",
    "    dev_mae.append(score_dev[2])\n",
    "    test1_mae.append(score_test1[2])\n",
    "\n",
    "    # organize newly created score dataset\n",
    "    model_scores['TRAIN_MSE'] = train_mse\n",
    "    model_scores['DEV_MSE'] = dev_mse\n",
    "    model_scores['TEST1_MSE'] = test1_mse\n",
    "\n",
    "    model_scores['TRAIN_MAE'] = train_mae\n",
    "    model_scores['DEV_MAE'] = dev_mae\n",
    "    model_scores['TEST1_MAE'] = test1_mae\n",
    "\n",
    "    # save newly created score dataset\n",
    "    model_scores_df = pd.DataFrame(model_scores)\n",
    "    model_scores_df.to_csv(\"D:/Course content/Minor Project/models/\"+d+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('D:/Course content/Minor Project/models/MLP.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"TRAIN_MSE\", \"DEV_MSE\", \"TEST1_MSE\", \"TRAIN_MAE\",\"DEV_MAE\", \"TEST1_MAE\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
